apiVersion: v1
kind: Pod
metadata:
  name: job-googlenet-cpu-19-12-8-19-1
spec:
  containers:
  - name: job-googlenet-cpu-19-12-8-19-1
    image: lenhattan86/ira:cpu
    command:
    - "/bin/bash"
    - "-c"
    - "python tf_cnn_benchmarks.py --device=cpu --data_format=NHWC --num_warmup_batches=0  --model=googlenet --batch_size=8 --num_intra_threads=19 --num_batches=4000"
    - "python tf_cnn_benchmarks.py --device=cpu --data_format=NHWC --num_warmup_batches=0  --model=googlenet --batch_size=8 --num_intra_threads=19 --num_batches=4000"
    - "19000,0,12,0"
    - "1000,1,12,0"
    resources:
      requests:
        nvidia.com/gpu: 0
        cpu: 19.0
        memory: 12Gi
      limits:
        nvidia.com/gpu: 0
        cpu: 19.0
        memory: 12Gi
    volumeMounts:
    - name: nvidia-driver-384-98
      mountPath: /usr/local/nvidia
      readOnly: true
    - name: libcuda-so
      mountPath: /usr/lib/x86_64-linux-gnu/libcuda.so
    - name: libcuda-so-1
      mountPath: /usr/lib/x86_64-linux-gnu/libcuda.so.1
    - name: libcuda-so-384-98
      mountPath: /usr/lib/x86_64-linux-gnu/libcuda.so.384.98
      readOnly: true
  restartPolicy: Never
  volumes:
  - name: nvidia-driver-384-98
    hostPath:
      path: /usr/lib/nvidia-384
  - name: libcuda-so
    hostPath:
      path: /usr/lib/x86_64-linux-gnu/libcuda.so
  - name: libcuda-so-1
    hostPath:
      path: /usr/lib/x86_64-linux-gnu/libcuda.so.1
  - name: libcuda-so-384-98
    hostPath:
      path: /usr/lib/x86_64-linux-gnu/libcuda.so.384.98